{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cubic-words",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-james",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rising-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-toddler",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hired-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    return pd.read_csv(path, header = 0, delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "russian-private",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (25000, 3)\n",
      "Train Data Valeus: ['id' 'sentiment' 'review']\n",
      "Test Data Shape: (25000, 2)\n",
      "Test Data Valeus: ['id' 'review']\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "train_data = load_data(path = 'Data/Raw/labeledTrainData.tsv')\n",
    "print('Train Data Shape:', train_data.shape)\n",
    "print('Train Data Valeus:', train_data.columns.values)\n",
    "\n",
    "# Test Data\n",
    "test_data = load_data(path = 'Data/Raw/testData.tsv')\n",
    "print('Test Data Shape:', test_data.shape)\n",
    "print('Test Data Valeus:', test_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-robertson",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nonprofit-islam",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get stopwords list    \n",
    "stop_words = set(nlp.Defaults.stop_words)\n",
    "\n",
    "\n",
    "def cleanup(review):\n",
    "    \n",
    "    # Remove Markups\n",
    "    review =  BeautifulSoup(review).get_text()\n",
    "\n",
    "    # Remove Numbers\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "\n",
    "    # Conver to lowercase\n",
    "    review = review.lower()\n",
    "\n",
    "    # Lemmatize\n",
    "    review = [token.lemma_ for token in nlp(review)]\n",
    "\n",
    "    # Remove stop words\n",
    "    review = [word for word in review if not word in stop_words]\n",
    "\n",
    "    # Rejoin the review words into one string\n",
    "    review = ' '.join(review)\n",
    "\n",
    "    return review\n",
    "\n",
    "def process_data(data, data_type):\n",
    "    \n",
    "    # Create a new DataFrame\n",
    "    cleaned_data = data.copy()    \n",
    "    \n",
    "    reviews = []\n",
    "    for i, review in enumerate(data['review']):\n",
    "        cleaned_review = cleanup(review)\n",
    "        reviews.append(cleaned_review)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Processing \"{data_type}\", {i} Review...')\n",
    "            \n",
    "    cleaned_data['review'] = reviews\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "herbal-cornell",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"Train Data\", 0 Review...\n",
      "Processing \"Train Data\", 100 Review...\n",
      "Processing \"Train Data\", 200 Review...\n",
      "Processing \"Train Data\", 300 Review...\n",
      "Processing \"Train Data\", 400 Review...\n",
      "Processing \"Train Data\", 500 Review...\n",
      "Processing \"Train Data\", 600 Review...\n",
      "Processing \"Train Data\", 700 Review...\n",
      "Processing \"Train Data\", 800 Review...\n",
      "Processing \"Train Data\", 900 Review...\n",
      "Processing \"Train Data\", 1000 Review...\n",
      "Processing \"Train Data\", 1100 Review...\n",
      "Processing \"Train Data\", 1200 Review...\n",
      "Processing \"Train Data\", 1300 Review...\n",
      "Processing \"Train Data\", 1400 Review...\n",
      "Processing \"Train Data\", 1500 Review...\n",
      "Processing \"Train Data\", 1600 Review...\n",
      "Processing \"Train Data\", 1700 Review...\n",
      "Processing \"Train Data\", 1800 Review...\n",
      "Processing \"Train Data\", 1900 Review...\n",
      "Processing \"Train Data\", 2000 Review...\n",
      "Processing \"Train Data\", 2100 Review...\n",
      "Processing \"Train Data\", 2200 Review...\n",
      "Processing \"Train Data\", 2300 Review...\n",
      "Processing \"Train Data\", 2400 Review...\n",
      "Processing \"Train Data\", 2500 Review...\n",
      "Processing \"Train Data\", 2600 Review...\n",
      "Processing \"Train Data\", 2700 Review...\n",
      "Processing \"Train Data\", 2800 Review...\n",
      "Processing \"Train Data\", 2900 Review...\n",
      "Processing \"Train Data\", 3000 Review...\n",
      "Processing \"Train Data\", 3100 Review...\n",
      "Processing \"Train Data\", 3200 Review...\n",
      "Processing \"Train Data\", 3300 Review...\n",
      "Processing \"Train Data\", 3400 Review...\n",
      "Processing \"Train Data\", 3500 Review...\n",
      "Processing \"Train Data\", 3600 Review...\n",
      "Processing \"Train Data\", 3700 Review...\n",
      "Processing \"Train Data\", 3800 Review...\n",
      "Processing \"Train Data\", 3900 Review...\n",
      "Processing \"Train Data\", 4000 Review...\n",
      "Processing \"Train Data\", 4100 Review...\n",
      "Processing \"Train Data\", 4200 Review...\n",
      "Processing \"Train Data\", 4300 Review...\n",
      "Processing \"Train Data\", 4400 Review...\n",
      "Processing \"Train Data\", 4500 Review...\n",
      "Processing \"Train Data\", 4600 Review...\n",
      "Processing \"Train Data\", 4700 Review...\n",
      "Processing \"Train Data\", 4800 Review...\n",
      "Processing \"Train Data\", 4900 Review...\n",
      "Processing \"Train Data\", 5000 Review...\n",
      "Processing \"Train Data\", 5100 Review...\n",
      "Processing \"Train Data\", 5200 Review...\n",
      "Processing \"Train Data\", 5300 Review...\n",
      "Processing \"Train Data\", 5400 Review...\n",
      "Processing \"Train Data\", 5500 Review...\n",
      "Processing \"Train Data\", 5600 Review...\n",
      "Processing \"Train Data\", 5700 Review...\n",
      "Processing \"Train Data\", 5800 Review...\n",
      "Processing \"Train Data\", 5900 Review...\n",
      "Processing \"Train Data\", 6000 Review...\n",
      "Processing \"Train Data\", 6100 Review...\n",
      "Processing \"Train Data\", 6200 Review...\n",
      "Processing \"Train Data\", 6300 Review...\n",
      "Processing \"Train Data\", 6400 Review...\n",
      "Processing \"Train Data\", 6500 Review...\n",
      "Processing \"Train Data\", 6600 Review...\n",
      "Processing \"Train Data\", 6700 Review...\n",
      "Processing \"Train Data\", 6800 Review...\n",
      "Processing \"Train Data\", 6900 Review...\n",
      "Processing \"Train Data\", 7000 Review...\n",
      "Processing \"Train Data\", 7100 Review...\n",
      "Processing \"Train Data\", 7200 Review...\n",
      "Processing \"Train Data\", 7300 Review...\n",
      "Processing \"Train Data\", 7400 Review...\n",
      "Processing \"Train Data\", 7500 Review...\n",
      "Processing \"Train Data\", 7600 Review...\n",
      "Processing \"Train Data\", 7700 Review...\n",
      "Processing \"Train Data\", 7800 Review...\n",
      "Processing \"Train Data\", 7900 Review...\n",
      "Processing \"Train Data\", 8000 Review...\n",
      "Processing \"Train Data\", 8100 Review...\n",
      "Processing \"Train Data\", 8200 Review...\n",
      "Processing \"Train Data\", 8300 Review...\n",
      "Processing \"Train Data\", 8400 Review...\n",
      "Processing \"Train Data\", 8500 Review...\n",
      "Processing \"Train Data\", 8600 Review...\n",
      "Processing \"Train Data\", 8700 Review...\n",
      "Processing \"Train Data\", 8800 Review...\n",
      "Processing \"Train Data\", 8900 Review...\n",
      "Processing \"Train Data\", 9000 Review...\n",
      "Processing \"Train Data\", 9100 Review...\n",
      "Processing \"Train Data\", 9200 Review...\n",
      "Processing \"Train Data\", 9300 Review...\n",
      "Processing \"Train Data\", 9400 Review...\n",
      "Processing \"Train Data\", 9500 Review...\n",
      "Processing \"Train Data\", 9600 Review...\n",
      "Processing \"Train Data\", 9700 Review...\n",
      "Processing \"Train Data\", 9800 Review...\n",
      "Processing \"Train Data\", 9900 Review...\n",
      "Processing \"Train Data\", 10000 Review...\n",
      "Processing \"Train Data\", 10100 Review...\n",
      "Processing \"Train Data\", 10200 Review...\n",
      "Processing \"Train Data\", 10300 Review...\n",
      "Processing \"Train Data\", 10400 Review...\n",
      "Processing \"Train Data\", 10500 Review...\n",
      "Processing \"Train Data\", 10600 Review...\n",
      "Processing \"Train Data\", 10700 Review...\n",
      "Processing \"Train Data\", 10800 Review...\n",
      "Processing \"Train Data\", 10900 Review...\n",
      "Processing \"Train Data\", 11000 Review...\n",
      "Processing \"Train Data\", 11100 Review...\n",
      "Processing \"Train Data\", 11200 Review...\n",
      "Processing \"Train Data\", 11300 Review...\n",
      "Processing \"Train Data\", 11400 Review...\n",
      "Processing \"Train Data\", 11500 Review...\n",
      "Processing \"Train Data\", 11600 Review...\n",
      "Processing \"Train Data\", 11700 Review...\n",
      "Processing \"Train Data\", 11800 Review...\n",
      "Processing \"Train Data\", 11900 Review...\n",
      "Processing \"Train Data\", 12000 Review...\n",
      "Processing \"Train Data\", 12100 Review...\n",
      "Processing \"Train Data\", 12200 Review...\n",
      "Processing \"Train Data\", 12300 Review...\n",
      "Processing \"Train Data\", 12400 Review...\n",
      "Processing \"Train Data\", 12500 Review...\n",
      "Processing \"Train Data\", 12600 Review...\n",
      "Processing \"Train Data\", 12700 Review...\n",
      "Processing \"Train Data\", 12800 Review...\n",
      "Processing \"Train Data\", 12900 Review...\n",
      "Processing \"Train Data\", 13000 Review...\n",
      "Processing \"Train Data\", 13100 Review...\n",
      "Processing \"Train Data\", 13200 Review...\n",
      "Processing \"Train Data\", 13300 Review...\n",
      "Processing \"Train Data\", 13400 Review...\n",
      "Processing \"Train Data\", 13500 Review...\n",
      "Processing \"Train Data\", 13600 Review...\n",
      "Processing \"Train Data\", 13700 Review...\n",
      "Processing \"Train Data\", 13800 Review...\n",
      "Processing \"Train Data\", 13900 Review...\n",
      "Processing \"Train Data\", 14000 Review...\n",
      "Processing \"Train Data\", 14100 Review...\n",
      "Processing \"Train Data\", 14200 Review...\n",
      "Processing \"Train Data\", 14300 Review...\n",
      "Processing \"Train Data\", 14400 Review...\n",
      "Processing \"Train Data\", 14500 Review...\n",
      "Processing \"Train Data\", 14600 Review...\n",
      "Processing \"Train Data\", 14700 Review...\n",
      "Processing \"Train Data\", 14800 Review...\n",
      "Processing \"Train Data\", 14900 Review...\n",
      "Processing \"Train Data\", 15000 Review...\n",
      "Processing \"Train Data\", 15100 Review...\n",
      "Processing \"Train Data\", 15200 Review...\n",
      "Processing \"Train Data\", 15300 Review...\n",
      "Processing \"Train Data\", 15400 Review...\n",
      "Processing \"Train Data\", 15500 Review...\n",
      "Processing \"Train Data\", 15600 Review...\n",
      "Processing \"Train Data\", 15700 Review...\n",
      "Processing \"Train Data\", 15800 Review...\n",
      "Processing \"Train Data\", 15900 Review...\n",
      "Processing \"Train Data\", 16000 Review...\n",
      "Processing \"Train Data\", 16100 Review...\n",
      "Processing \"Train Data\", 16200 Review...\n",
      "Processing \"Train Data\", 16300 Review...\n",
      "Processing \"Train Data\", 16400 Review...\n",
      "Processing \"Train Data\", 16500 Review...\n",
      "Processing \"Train Data\", 16600 Review...\n",
      "Processing \"Train Data\", 16700 Review...\n",
      "Processing \"Train Data\", 16800 Review...\n",
      "Processing \"Train Data\", 16900 Review...\n",
      "Processing \"Train Data\", 17000 Review...\n",
      "Processing \"Train Data\", 17100 Review...\n",
      "Processing \"Train Data\", 17200 Review...\n",
      "Processing \"Train Data\", 17300 Review...\n",
      "Processing \"Train Data\", 17400 Review...\n",
      "Processing \"Train Data\", 17500 Review...\n",
      "Processing \"Train Data\", 17600 Review...\n",
      "Processing \"Train Data\", 17700 Review...\n",
      "Processing \"Train Data\", 17800 Review...\n",
      "Processing \"Train Data\", 17900 Review...\n",
      "Processing \"Train Data\", 18000 Review...\n",
      "Processing \"Train Data\", 18100 Review...\n",
      "Processing \"Train Data\", 18200 Review...\n",
      "Processing \"Train Data\", 18300 Review...\n",
      "Processing \"Train Data\", 18400 Review...\n",
      "Processing \"Train Data\", 18500 Review...\n",
      "Processing \"Train Data\", 18600 Review...\n",
      "Processing \"Train Data\", 18700 Review...\n",
      "Processing \"Train Data\", 18800 Review...\n",
      "Processing \"Train Data\", 18900 Review...\n",
      "Processing \"Train Data\", 19000 Review...\n",
      "Processing \"Train Data\", 19100 Review...\n",
      "Processing \"Train Data\", 19200 Review...\n",
      "Processing \"Train Data\", 19300 Review...\n",
      "Processing \"Train Data\", 19400 Review...\n",
      "Processing \"Train Data\", 19500 Review...\n",
      "Processing \"Train Data\", 19600 Review...\n",
      "Processing \"Train Data\", 19700 Review...\n",
      "Processing \"Train Data\", 19800 Review...\n",
      "Processing \"Train Data\", 19900 Review...\n",
      "Processing \"Train Data\", 20000 Review...\n",
      "Processing \"Train Data\", 20100 Review...\n",
      "Processing \"Train Data\", 20200 Review...\n",
      "Processing \"Train Data\", 20300 Review...\n",
      "Processing \"Train Data\", 20400 Review...\n",
      "Processing \"Train Data\", 20500 Review...\n",
      "Processing \"Train Data\", 20600 Review...\n",
      "Processing \"Train Data\", 20700 Review...\n",
      "Processing \"Train Data\", 20800 Review...\n",
      "Processing \"Train Data\", 20900 Review...\n",
      "Processing \"Train Data\", 21000 Review...\n",
      "Processing \"Train Data\", 21100 Review...\n",
      "Processing \"Train Data\", 21200 Review...\n",
      "Processing \"Train Data\", 21300 Review...\n",
      "Processing \"Train Data\", 21400 Review...\n",
      "Processing \"Train Data\", 21500 Review...\n",
      "Processing \"Train Data\", 21600 Review...\n",
      "Processing \"Train Data\", 21700 Review...\n",
      "Processing \"Train Data\", 21800 Review...\n",
      "Processing \"Train Data\", 21900 Review...\n",
      "Processing \"Train Data\", 22000 Review...\n",
      "Processing \"Train Data\", 22100 Review...\n",
      "Processing \"Train Data\", 22200 Review...\n",
      "Processing \"Train Data\", 22300 Review...\n",
      "Processing \"Train Data\", 22400 Review...\n",
      "Processing \"Train Data\", 22500 Review...\n",
      "Processing \"Train Data\", 22600 Review...\n",
      "Processing \"Train Data\", 22700 Review...\n",
      "Processing \"Train Data\", 22800 Review...\n",
      "Processing \"Train Data\", 22900 Review...\n",
      "Processing \"Train Data\", 23000 Review...\n",
      "Processing \"Train Data\", 23100 Review...\n",
      "Processing \"Train Data\", 23200 Review...\n",
      "Processing \"Train Data\", 23300 Review...\n",
      "Processing \"Train Data\", 23400 Review...\n",
      "Processing \"Train Data\", 23500 Review...\n",
      "Processing \"Train Data\", 23600 Review...\n",
      "Processing \"Train Data\", 23700 Review...\n",
      "Processing \"Train Data\", 23800 Review...\n",
      "Processing \"Train Data\", 23900 Review...\n",
      "Processing \"Train Data\", 24000 Review...\n",
      "Processing \"Train Data\", 24100 Review...\n",
      "Processing \"Train Data\", 24200 Review...\n",
      "Processing \"Train Data\", 24300 Review...\n",
      "Processing \"Train Data\", 24400 Review...\n",
      "Processing \"Train Data\", 24500 Review...\n",
      "Processing \"Train Data\", 24600 Review...\n",
      "Processing \"Train Data\", 24700 Review...\n",
      "Processing \"Train Data\", 24800 Review...\n",
      "Processing \"Train Data\", 24900 Review...\n",
      "Processing \"Test Data\", 0 Review...\n",
      "Processing \"Test Data\", 100 Review...\n",
      "Processing \"Test Data\", 200 Review...\n",
      "Processing \"Test Data\", 300 Review...\n",
      "Processing \"Test Data\", 400 Review...\n",
      "Processing \"Test Data\", 500 Review...\n",
      "Processing \"Test Data\", 600 Review...\n",
      "Processing \"Test Data\", 700 Review...\n",
      "Processing \"Test Data\", 800 Review...\n",
      "Processing \"Test Data\", 900 Review...\n",
      "Processing \"Test Data\", 1000 Review...\n",
      "Processing \"Test Data\", 1100 Review...\n",
      "Processing \"Test Data\", 1200 Review...\n",
      "Processing \"Test Data\", 1300 Review...\n",
      "Processing \"Test Data\", 1400 Review...\n",
      "Processing \"Test Data\", 1500 Review...\n",
      "Processing \"Test Data\", 1600 Review...\n",
      "Processing \"Test Data\", 1700 Review...\n",
      "Processing \"Test Data\", 1800 Review...\n",
      "Processing \"Test Data\", 1900 Review...\n",
      "Processing \"Test Data\", 2000 Review...\n",
      "Processing \"Test Data\", 2100 Review...\n",
      "Processing \"Test Data\", 2200 Review...\n",
      "Processing \"Test Data\", 2300 Review...\n",
      "Processing \"Test Data\", 2400 Review...\n",
      "Processing \"Test Data\", 2500 Review...\n",
      "Processing \"Test Data\", 2600 Review...\n",
      "Processing \"Test Data\", 2700 Review...\n",
      "Processing \"Test Data\", 2800 Review...\n",
      "Processing \"Test Data\", 2900 Review...\n",
      "Processing \"Test Data\", 3000 Review...\n",
      "Processing \"Test Data\", 3100 Review...\n",
      "Processing \"Test Data\", 3200 Review...\n",
      "Processing \"Test Data\", 3300 Review...\n",
      "Processing \"Test Data\", 3400 Review...\n",
      "Processing \"Test Data\", 3500 Review...\n",
      "Processing \"Test Data\", 3600 Review...\n",
      "Processing \"Test Data\", 3700 Review...\n",
      "Processing \"Test Data\", 3800 Review...\n",
      "Processing \"Test Data\", 3900 Review...\n",
      "Processing \"Test Data\", 4000 Review...\n",
      "Processing \"Test Data\", 4100 Review...\n",
      "Processing \"Test Data\", 4200 Review...\n",
      "Processing \"Test Data\", 4300 Review...\n",
      "Processing \"Test Data\", 4400 Review...\n",
      "Processing \"Test Data\", 4500 Review...\n",
      "Processing \"Test Data\", 4600 Review...\n",
      "Processing \"Test Data\", 4700 Review...\n",
      "Processing \"Test Data\", 4800 Review...\n",
      "Processing \"Test Data\", 4900 Review...\n",
      "Processing \"Test Data\", 5000 Review...\n",
      "Processing \"Test Data\", 5100 Review...\n",
      "Processing \"Test Data\", 5200 Review...\n",
      "Processing \"Test Data\", 5300 Review...\n",
      "Processing \"Test Data\", 5400 Review...\n",
      "Processing \"Test Data\", 5500 Review...\n",
      "Processing \"Test Data\", 5600 Review...\n",
      "Processing \"Test Data\", 5700 Review...\n",
      "Processing \"Test Data\", 5800 Review...\n",
      "Processing \"Test Data\", 5900 Review...\n",
      "Processing \"Test Data\", 6000 Review...\n",
      "Processing \"Test Data\", 6100 Review...\n",
      "Processing \"Test Data\", 6200 Review...\n",
      "Processing \"Test Data\", 6300 Review...\n",
      "Processing \"Test Data\", 6400 Review...\n",
      "Processing \"Test Data\", 6500 Review...\n",
      "Processing \"Test Data\", 6600 Review...\n",
      "Processing \"Test Data\", 6700 Review...\n",
      "Processing \"Test Data\", 6800 Review...\n",
      "Processing \"Test Data\", 6900 Review...\n",
      "Processing \"Test Data\", 7000 Review...\n",
      "Processing \"Test Data\", 7100 Review...\n",
      "Processing \"Test Data\", 7200 Review...\n",
      "Processing \"Test Data\", 7300 Review...\n",
      "Processing \"Test Data\", 7400 Review...\n",
      "Processing \"Test Data\", 7500 Review...\n",
      "Processing \"Test Data\", 7600 Review...\n",
      "Processing \"Test Data\", 7700 Review...\n",
      "Processing \"Test Data\", 7800 Review...\n",
      "Processing \"Test Data\", 7900 Review...\n",
      "Processing \"Test Data\", 8000 Review...\n",
      "Processing \"Test Data\", 8100 Review...\n",
      "Processing \"Test Data\", 8200 Review...\n",
      "Processing \"Test Data\", 8300 Review...\n",
      "Processing \"Test Data\", 8400 Review...\n",
      "Processing \"Test Data\", 8500 Review...\n",
      "Processing \"Test Data\", 8600 Review...\n",
      "Processing \"Test Data\", 8700 Review...\n",
      "Processing \"Test Data\", 8800 Review...\n",
      "Processing \"Test Data\", 8900 Review...\n",
      "Processing \"Test Data\", 9000 Review...\n",
      "Processing \"Test Data\", 9100 Review...\n",
      "Processing \"Test Data\", 9200 Review...\n",
      "Processing \"Test Data\", 9300 Review...\n",
      "Processing \"Test Data\", 9400 Review...\n",
      "Processing \"Test Data\", 9500 Review...\n",
      "Processing \"Test Data\", 9600 Review...\n",
      "Processing \"Test Data\", 9700 Review...\n",
      "Processing \"Test Data\", 9800 Review...\n",
      "Processing \"Test Data\", 9900 Review...\n",
      "Processing \"Test Data\", 10000 Review...\n",
      "Processing \"Test Data\", 10100 Review...\n",
      "Processing \"Test Data\", 10200 Review...\n",
      "Processing \"Test Data\", 10300 Review...\n",
      "Processing \"Test Data\", 10400 Review...\n",
      "Processing \"Test Data\", 10500 Review...\n",
      "Processing \"Test Data\", 10600 Review...\n",
      "Processing \"Test Data\", 10700 Review...\n",
      "Processing \"Test Data\", 10800 Review...\n",
      "Processing \"Test Data\", 10900 Review...\n",
      "Processing \"Test Data\", 11000 Review...\n",
      "Processing \"Test Data\", 11100 Review...\n",
      "Processing \"Test Data\", 11200 Review...\n",
      "Processing \"Test Data\", 11300 Review...\n",
      "Processing \"Test Data\", 11400 Review...\n",
      "Processing \"Test Data\", 11500 Review...\n",
      "Processing \"Test Data\", 11600 Review...\n",
      "Processing \"Test Data\", 11700 Review...\n",
      "Processing \"Test Data\", 11800 Review...\n",
      "Processing \"Test Data\", 11900 Review...\n",
      "Processing \"Test Data\", 12000 Review...\n",
      "Processing \"Test Data\", 12100 Review...\n",
      "Processing \"Test Data\", 12200 Review...\n",
      "Processing \"Test Data\", 12300 Review...\n",
      "Processing \"Test Data\", 12400 Review...\n",
      "Processing \"Test Data\", 12500 Review...\n",
      "Processing \"Test Data\", 12600 Review...\n",
      "Processing \"Test Data\", 12700 Review...\n",
      "Processing \"Test Data\", 12800 Review...\n",
      "Processing \"Test Data\", 12900 Review...\n",
      "Processing \"Test Data\", 13000 Review...\n",
      "Processing \"Test Data\", 13100 Review...\n",
      "Processing \"Test Data\", 13200 Review...\n",
      "Processing \"Test Data\", 13300 Review...\n",
      "Processing \"Test Data\", 13400 Review...\n",
      "Processing \"Test Data\", 13500 Review...\n",
      "Processing \"Test Data\", 13600 Review...\n",
      "Processing \"Test Data\", 13700 Review...\n",
      "Processing \"Test Data\", 13800 Review...\n",
      "Processing \"Test Data\", 13900 Review...\n",
      "Processing \"Test Data\", 14000 Review...\n",
      "Processing \"Test Data\", 14100 Review...\n",
      "Processing \"Test Data\", 14200 Review...\n",
      "Processing \"Test Data\", 14300 Review...\n",
      "Processing \"Test Data\", 14400 Review...\n",
      "Processing \"Test Data\", 14500 Review...\n",
      "Processing \"Test Data\", 14600 Review...\n",
      "Processing \"Test Data\", 14700 Review...\n",
      "Processing \"Test Data\", 14800 Review...\n",
      "Processing \"Test Data\", 14900 Review...\n",
      "Processing \"Test Data\", 15000 Review...\n",
      "Processing \"Test Data\", 15100 Review...\n",
      "Processing \"Test Data\", 15200 Review...\n",
      "Processing \"Test Data\", 15300 Review...\n",
      "Processing \"Test Data\", 15400 Review...\n",
      "Processing \"Test Data\", 15500 Review...\n",
      "Processing \"Test Data\", 15600 Review...\n",
      "Processing \"Test Data\", 15700 Review...\n",
      "Processing \"Test Data\", 15800 Review...\n",
      "Processing \"Test Data\", 15900 Review...\n",
      "Processing \"Test Data\", 16000 Review...\n",
      "Processing \"Test Data\", 16100 Review...\n",
      "Processing \"Test Data\", 16200 Review...\n",
      "Processing \"Test Data\", 16300 Review...\n",
      "Processing \"Test Data\", 16400 Review...\n",
      "Processing \"Test Data\", 16500 Review...\n",
      "Processing \"Test Data\", 16600 Review...\n",
      "Processing \"Test Data\", 16700 Review...\n",
      "Processing \"Test Data\", 16800 Review...\n",
      "Processing \"Test Data\", 16900 Review...\n",
      "Processing \"Test Data\", 17000 Review...\n",
      "Processing \"Test Data\", 17100 Review...\n",
      "Processing \"Test Data\", 17200 Review...\n",
      "Processing \"Test Data\", 17300 Review...\n",
      "Processing \"Test Data\", 17400 Review...\n",
      "Processing \"Test Data\", 17500 Review...\n",
      "Processing \"Test Data\", 17600 Review...\n",
      "Processing \"Test Data\", 17700 Review...\n",
      "Processing \"Test Data\", 17800 Review...\n",
      "Processing \"Test Data\", 17900 Review...\n",
      "Processing \"Test Data\", 18000 Review...\n",
      "Processing \"Test Data\", 18100 Review...\n",
      "Processing \"Test Data\", 18200 Review...\n",
      "Processing \"Test Data\", 18300 Review...\n",
      "Processing \"Test Data\", 18400 Review...\n",
      "Processing \"Test Data\", 18500 Review...\n",
      "Processing \"Test Data\", 18600 Review...\n",
      "Processing \"Test Data\", 18700 Review...\n",
      "Processing \"Test Data\", 18800 Review...\n",
      "Processing \"Test Data\", 18900 Review...\n",
      "Processing \"Test Data\", 19000 Review...\n",
      "Processing \"Test Data\", 19100 Review...\n",
      "Processing \"Test Data\", 19200 Review...\n",
      "Processing \"Test Data\", 19300 Review...\n",
      "Processing \"Test Data\", 19400 Review...\n",
      "Processing \"Test Data\", 19500 Review...\n",
      "Processing \"Test Data\", 19600 Review...\n",
      "Processing \"Test Data\", 19700 Review...\n",
      "Processing \"Test Data\", 19800 Review...\n",
      "Processing \"Test Data\", 19900 Review...\n",
      "Processing \"Test Data\", 20000 Review...\n",
      "Processing \"Test Data\", 20100 Review...\n",
      "Processing \"Test Data\", 20200 Review...\n",
      "Processing \"Test Data\", 20300 Review...\n",
      "Processing \"Test Data\", 20400 Review...\n",
      "Processing \"Test Data\", 20500 Review...\n",
      "Processing \"Test Data\", 20600 Review...\n",
      "Processing \"Test Data\", 20700 Review...\n",
      "Processing \"Test Data\", 20800 Review...\n",
      "Processing \"Test Data\", 20900 Review...\n",
      "Processing \"Test Data\", 21000 Review...\n",
      "Processing \"Test Data\", 21100 Review...\n",
      "Processing \"Test Data\", 21200 Review...\n",
      "Processing \"Test Data\", 21300 Review...\n",
      "Processing \"Test Data\", 21400 Review...\n",
      "Processing \"Test Data\", 21500 Review...\n",
      "Processing \"Test Data\", 21600 Review...\n",
      "Processing \"Test Data\", 21700 Review...\n",
      "Processing \"Test Data\", 21800 Review...\n",
      "Processing \"Test Data\", 21900 Review...\n",
      "Processing \"Test Data\", 22000 Review...\n",
      "Processing \"Test Data\", 22100 Review...\n",
      "Processing \"Test Data\", 22200 Review...\n",
      "Processing \"Test Data\", 22300 Review...\n",
      "Processing \"Test Data\", 22400 Review...\n",
      "Processing \"Test Data\", 22500 Review...\n",
      "Processing \"Test Data\", 22600 Review...\n",
      "Processing \"Test Data\", 22700 Review...\n",
      "Processing \"Test Data\", 22800 Review...\n",
      "Processing \"Test Data\", 22900 Review...\n",
      "Processing \"Test Data\", 23000 Review...\n",
      "Processing \"Test Data\", 23100 Review...\n",
      "Processing \"Test Data\", 23200 Review...\n",
      "Processing \"Test Data\", 23300 Review...\n",
      "Processing \"Test Data\", 23400 Review...\n",
      "Processing \"Test Data\", 23500 Review...\n",
      "Processing \"Test Data\", 23600 Review...\n",
      "Processing \"Test Data\", 23700 Review...\n",
      "Processing \"Test Data\", 23800 Review...\n",
      "Processing \"Test Data\", 23900 Review...\n",
      "Processing \"Test Data\", 24000 Review...\n",
      "Processing \"Test Data\", 24100 Review...\n",
      "Processing \"Test Data\", 24200 Review...\n",
      "Processing \"Test Data\", 24300 Review...\n",
      "Processing \"Test Data\", 24400 Review...\n",
      "Processing \"Test Data\", 24500 Review...\n",
      "Processing \"Test Data\", 24600 Review...\n",
      "Processing \"Test Data\", 24700 Review...\n",
      "Processing \"Test Data\", 24800 Review...\n",
      "Processing \"Test Data\", 24900 Review...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>naturally film s main theme mortality   nost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>movie disaster disaster film   great action ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>movie kid   tonight child love   point kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>afraid dark leave I impression different scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>accurate depiction small time mob life film ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"    naturally film s main theme mortality   nost...\n",
       "1    \"8348_2\"    movie disaster disaster film   great action ...\n",
       "2    \"5828_4\"      movie kid   tonight child love   point kid...\n",
       "3    \"7186_2\"    afraid dark leave I impression different scr...\n",
       "4   \"12128_7\"    accurate depiction small time mob life film ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data\n",
    "cleaned_train_data = process_data(train_data, data_type = 'Train Data')\n",
    "cleaned_train_data.head(5)\n",
    "\n",
    "# Test Data\n",
    "cleaned_test_data = process_data(data = test_data, data_type = 'Test Data')\n",
    "cleaned_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-planning",
   "metadata": {},
   "source": [
    "## Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranging-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data.to_csv('Data/Processed/cleaned_labeledTrainData.csv', index = False)\n",
    "cleaned_test_data.to_csv('Data/Processed/cleaned_testData.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-intellectual",
   "metadata": {},
   "source": [
    "## Load the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "painful-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data = pd.read_csv('Data/Processed/cleaned_labeledTrainData.csv')\n",
    "cleaned_test_data = pd.read_csv('Data/Processed/cleaned_testData.csv')\n",
    "\n",
    "cleaned_train_reviews = cleaned_train_data['review']\n",
    "cleaned_test_reviews = cleaned_test_data['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-rental",
   "metadata": {},
   "source": [
    "## Vectorize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-power",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clean-street",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features = 5000)      # Top 5000 frequent words\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(cleaned_train_reviews)\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indian-reverse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abc',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abound',\n",
       " 'abraham',\n",
       " 'abrupt',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'abysmal',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'acclaim',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acid',\n",
       " 'acknowledge',\n",
       " 'acquire',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adequate',\n",
       " 'admirable',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admit',\n",
       " 'admittedly',\n",
       " 'adolescent',\n",
       " 'adopt',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advertise',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affleck',\n",
       " 'afford',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'akshay',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alec',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alfre',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alike',\n",
       " 'alison',\n",
       " 'alive',\n",
       " 'allen',\n",
       " 'alley',\n",
       " 'allow',\n",
       " 'ally',\n",
       " 'alongside',\n",
       " 'alright',\n",
       " 'alter',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'alvin',\n",
       " 'amanda',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amitabh',\n",
       " 'amuse',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'andre',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'andy',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angele',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'animal',\n",
       " 'animate',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animator',\n",
       " 'anime',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'announce',\n",
       " 'annoy',\n",
       " 'annoying',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antagonist',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antic',\n",
       " 'anticipate',\n",
       " 'anticipation',\n",
       " 'anton',\n",
       " 'antonio',\n",
       " 'antonioni',\n",
       " 'antwone',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyways',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'ape',\n",
       " 'appal',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'april',\n",
       " 'arab',\n",
       " 'arc',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'ariel',\n",
       " 'arise',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'arnold',\n",
       " 'arrange',\n",
       " 'arrest',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artsy',\n",
       " 'artwork',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspire',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assemble',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'assume',\n",
       " 'assure',\n",
       " 'astaire',\n",
       " 'astonishing',\n",
       " 'astronaut',\n",
       " 'asylum',\n",
       " 'atlantis',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attenborough',\n",
       " 'attend',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audition',\n",
       " 'audrey',\n",
       " 'aunt',\n",
       " 'aussie',\n",
       " 'austen',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'authentic',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'avenge',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'axe',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'bacall',\n",
       " 'bach',\n",
       " 'bachelor',\n",
       " 'backdrop',\n",
       " 'background',\n",
       " 'backwards',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'baddie',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'baker',\n",
       " 'bakshi',\n",
       " 'balance',\n",
       " 'baldwin',\n",
       " 'ball',\n",
       " 'ballet',\n",
       " 'ban',\n",
       " 'banal',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'banter',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'barrel',\n",
       " 'barry',\n",
       " 'barrymore',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basinger',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bat',\n",
       " 'bate',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battle',\n",
       " 'bay',\n",
       " 'bbc',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beatle',\n",
       " 'beatty',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'beer',\n",
       " 'befriend',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behave',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behold',\n",
       " 'bela',\n",
       " 'belief',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'belushi',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'bent',\n",
       " 'bergman',\n",
       " 'berlin',\n",
       " 'bernard',\n",
       " 'bet',\n",
       " 'betray',\n",
       " 'betrayal',\n",
       " 'bette',\n",
       " 'bettie',\n",
       " 'betty',\n",
       " 'beverly',\n",
       " 'beware',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'biblical',\n",
       " 'big',\n",
       " 'bike',\n",
       " 'biker',\n",
       " 'biko',\n",
       " 'bill',\n",
       " 'billy',\n",
       " 'bin',\n",
       " 'bind',\n",
       " 'biography',\n",
       " 'biopic',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blackmail',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blair',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blank',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'bleak',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blind',\n",
       " 'blob',\n",
       " 'block',\n",
       " 'blockbuster',\n",
       " 'blond',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'bloom',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blunt',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boast',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bobby',\n",
       " 'body',\n",
       " 'bogus',\n",
       " 'boil',\n",
       " 'bold',\n",
       " 'boll',\n",
       " 'bollywood',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bondage',\n",
       " 'bone',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'boom',\n",
       " 'boot',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boredom',\n",
       " 'boring',\n",
       " 'boris',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bounce',\n",
       " 'bourne',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxer',\n",
       " 'boxing',\n",
       " 'boy',\n",
       " 'boyer',\n",
       " 'boyfriend',\n",
       " 'boyle',\n",
       " 'brad',\n",
       " 'brady',\n",
       " 'brain',\n",
       " 'branagh',\n",
       " 'brand',\n",
       " 'brando',\n",
       " 'brave',\n",
       " 'braveheart',\n",
       " 'bravo',\n",
       " 'brazil',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathtake',\n",
       " 'breathtaking',\n",
       " 'breed',\n",
       " 'brenda',\n",
       " 'brendan',\n",
       " 'brian',\n",
       " 'bride',\n",
       " 'bridge',\n",
       " 'bridget',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'bright',\n",
       " 'brilliance',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'bring',\n",
       " 'brit',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broadway',\n",
       " 'broken',\n",
       " 'bronson',\n",
       " 'brook',\n",
       " 'brooklyn',\n",
       " 'brosnan',\n",
       " 'brother',\n",
       " 'brown',\n",
       " 'bruce',\n",
       " 'brush',\n",
       " 'brutal',\n",
       " 'brutality',\n",
       " 'brutally',\n",
       " 'bsg',\n",
       " 'btw',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buff',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bulk',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bully',\n",
       " 'bumble',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bunny',\n",
       " 'burn',\n",
       " 'burst',\n",
       " 'burt',\n",
       " 'burton',\n",
       " 'bury',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'businessman',\n",
       " 'bust',\n",
       " 'buster',\n",
       " 'busy',\n",
       " 'butcher',\n",
       " 'butler',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'bye',\n",
       " 'cabin',\n",
       " 'cable',\n",
       " 'cage',\n",
       " 'cagney',\n",
       " 'cain',\n",
       " 'caine',\n",
       " 'cake',\n",
       " 'caliber',\n",
       " 'california',\n",
       " 'calm',\n",
       " 'camcorder',\n",
       " 'cameo',\n",
       " 'camera',\n",
       " 'cameraman',\n",
       " 'cameron',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campbell',\n",
       " 'campy',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candle',\n",
       " 'candy',\n",
       " 'cannibal',\n",
       " 'cannon',\n",
       " 'canyon',\n",
       " 'cap',\n",
       " 'capable',\n",
       " 'cape',\n",
       " 'capital',\n",
       " 'capote',\n",
       " 'captain',\n",
       " 'captivate',\n",
       " 'capture',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardboard',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'carell',\n",
       " 'carey',\n",
       " 'caricature',\n",
       " 'carl',\n",
       " 'carla',\n",
       " 'carlito',\n",
       " 'carol',\n",
       " 'carpenter',\n",
       " 'carradine',\n",
       " 'carrey',\n",
       " 'carrie',\n",
       " 'carry',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'cartoonish',\n",
       " 'cary',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'casino',\n",
       " 'casper',\n",
       " 'cassavete',\n",
       " 'cassidy',\n",
       " 'cast',\n",
       " 'casting',\n",
       " 'castle',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catchy',\n",
       " 'category',\n",
       " 'catherine',\n",
       " 'catholic',\n",
       " 'cattle',\n",
       " 'cause',\n",
       " 'cave',\n",
       " 'cbs',\n",
       " 'cd',\n",
       " 'cecil',\n",
       " 'celebrate',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'celluloid',\n",
       " 'cemetery',\n",
       " 'censor',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'century',\n",
       " 'cerebral',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'cg',\n",
       " 'cgi',\n",
       " 'chain',\n",
       " 'chainsaw',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'chamberlain',\n",
       " 'champion',\n",
       " 'championship',\n",
       " 'chan',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'chaplin',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'characterisation',\n",
       " 'characteristic',\n",
       " 'characterization',\n",
       " 'charge',\n",
       " 'charisma',\n",
       " 'charismatic',\n",
       " 'charle',\n",
       " 'charles',\n",
       " 'charlie',\n",
       " 'charlotte',\n",
       " 'charlton',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chase',\n",
       " 'chavez',\n",
       " 'che',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'cheek',\n",
       " 'cheer',\n",
       " 'cheese',\n",
       " 'cheesy',\n",
       " 'chemistry',\n",
       " 'cher',\n",
       " 'chess',\n",
       " 'chest',\n",
       " 'chew',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'childish',\n",
       " 'chill',\n",
       " 'chilling',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'choice',\n",
       " 'choke',\n",
       " 'choose',\n",
       " 'chop',\n",
       " 'choppy',\n",
       " 'choreographed',\n",
       " 'choreography',\n",
       " 'chorus',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christianity',\n",
       " 'christie',\n",
       " 'christina',\n",
       " 'christine',\n",
       " 'christma',\n",
       " 'christmas',\n",
       " 'christopher',\n",
       " 'christy',\n",
       " 'chronicle',\n",
       " 'chuck',\n",
       " 'chuckle',\n",
       " 'church',\n",
       " 'cia',\n",
       " 'cigarette',\n",
       " 'cinderella',\n",
       " 'cinema',\n",
       " 'cinematic',\n",
       " 'cinematographer',\n",
       " 'cinematography',\n",
       " 'circle',\n",
       " 'circumstance',\n",
       " 'circus',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'civilization',\n",
       " 'claim',\n",
       " 'claire',\n",
       " 'clan',\n",
       " 'clara',\n",
       " 'clark',\n",
       " 'clarke',\n",
       " 'clash',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classical',\n",
       " 'claude',\n",
       " 'claus',\n",
       " 'claustrophobic',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clerk',\n",
       " 'clever',\n",
       " 'cleverly',\n",
       " 'clich',\n",
       " 'cliche',\n",
       " 'click',\n",
       " 'client',\n",
       " 'cliff',\n",
       " 'cliffhanger',\n",
       " 'climactic',\n",
       " 'climax',\n",
       " 'climb',\n",
       " 'clint',\n",
       " 'clip',\n",
       " 'clock',\n",
       " 'clone',\n",
       " 'close',\n",
       " 'closely',\n",
       " 'closet',\n",
       " 'closing',\n",
       " 'clothe',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'clumsy',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coast',\n",
       " 'coaster',\n",
       " 'coat',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cohen',\n",
       " 'coherent',\n",
       " 'coincidence',\n",
       " 'cold',\n",
       " 'cole',\n",
       " 'colin',\n",
       " 'collapse',\n",
       " 'colleague',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'collector',\n",
       " 'college',\n",
       " 'colonel',\n",
       " 'colony',\n",
       " 'color',\n",
       " 'colorful',\n",
       " 'colour',\n",
       " 'columbo',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'come',\n",
       " 'comedian',\n",
       " 'comedic',\n",
       " 'comedy',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comic',\n",
       " 'comic_strip',\n",
       " 'comical',\n",
       " 'command',\n",
       " 'commander',\n",
       " 'comment',\n",
       " 'commentary',\n",
       " 'commercial',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'common',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'comparison',\n",
       " 'compassion',\n",
       " 'compel',\n",
       " 'compelling',\n",
       " 'compensate',\n",
       " 'compete',\n",
       " 'competent',\n",
       " 'competition',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'complicated',\n",
       " 'compliment',\n",
       " 'compose',\n",
       " 'composer',\n",
       " 'composition',\n",
       " 'comprehend',\n",
       " 'comprise',\n",
       " 'compromise',\n",
       " 'computer',\n",
       " 'con',\n",
       " 'conan',\n",
       " 'conceive',\n",
       " 'concentrate',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concert',\n",
       " 'conclude',\n",
       " 'conclusion',\n",
       " 'condemn',\n",
       " 'condition',\n",
       " 'conduct',\n",
       " 'confess',\n",
       " 'confession',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confine',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'confront',\n",
       " 'confrontation',\n",
       " 'confuse',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'confusion',\n",
       " 'connect',\n",
       " 'connection',\n",
       " 'connery',\n",
       " 'connor',\n",
       " 'conquer',\n",
       " 'conrad',\n",
       " 'conscience',\n",
       " 'conscious',\n",
       " 'consequence',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'considerable',\n",
       " 'considerably',\n",
       " 'consideration',\n",
       " 'consist',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'construct',\n",
       " 'construction',\n",
       " 'consume',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'contemplate',\n",
       " 'contemporary',\n",
       " 'contempt',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'contestant',\n",
       " 'context',\n",
       " 'continually',\n",
       " 'continue',\n",
       " 'continuity',\n",
       " 'contract',\n",
       " 'contrary',\n",
       " 'contrast',\n",
       " 'contribute',\n",
       " 'contribution',\n",
       " 'contrive',\n",
       " 'contrived',\n",
       " 'control',\n",
       " 'controversial',\n",
       " 'convention',\n",
       " 'conventional',\n",
       " 'conversation',\n",
       " 'convey',\n",
       " 'convict',\n",
       " 'conviction',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'convincing',\n",
       " 'convincingly',\n",
       " 'convoluted',\n",
       " 'cook',\n",
       " 'cookie',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-external",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "traditional-connecticut",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(cleaned_test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-single",
   "metadata": {},
   "source": [
    "## Train the Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "critical-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 100)\n",
    "random_forest = random_forest.fit(train_data_features, cleaned_train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-extension",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = random_forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-offering",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "golden-liability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2913_8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4396_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>395_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10616_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9074_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment\n",
       "0  12311_10          1\n",
       "1    8348_2          0\n",
       "2    5828_4          1\n",
       "3    7186_2          0\n",
       "4   12128_7          1\n",
       "5    2913_8          1\n",
       "6    4396_1          0\n",
       "7     395_2          1\n",
       "8   10616_1          0\n",
       "9    9074_9          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_data['id'] = cleaned_test_data['id'].apply(lambda x: re.sub('\"', \"\", x))\n",
    "\n",
    "predictions_df = pd.DataFrame(data = {'id': cleaned_test_data['id'], 'sentiment': predictions})\n",
    "predictions_df.to_csv('Data/Processed/Submission.csv', index = False)\n",
    "predictions_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

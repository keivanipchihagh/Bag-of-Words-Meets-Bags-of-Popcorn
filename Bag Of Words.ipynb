{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "military-google",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-cheese",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "persistent-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-looking",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afraid-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    return pd.read_csv(path, header = 0, delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "checked-yemen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (25000, 3)\n",
      "Train Data Valeus: ['id' 'sentiment' 'review']\n",
      "Test Data Shape: (25000, 2)\n",
      "Test Data Valeus: ['id' 'review']\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "train_data = load_data(path = 'Data/Raw/labeledTrainData.tsv')\n",
    "print('Train Data Shape:', train_data.shape)\n",
    "print('Train Data Valeus:', train_data.columns.values)\n",
    "\n",
    "# Test Data\n",
    "test_data = load_data(path = 'Data/Raw/testData.tsv')\n",
    "print('Test Data Shape:', test_data.shape)\n",
    "print('Test Data Valeus:', test_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-employment",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southwest-vehicle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get stopwords list    \n",
    "stop_words = set(nlp.Defaults.stop_words)\n",
    "\n",
    "\n",
    "def cleanup(review):\n",
    "    \n",
    "    # Remove Markups\n",
    "    review =  BeautifulSoup(review).get_text()\n",
    "\n",
    "    # Remove Numbers\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "\n",
    "    # Conver to lowercase\n",
    "    review = review.lower()\n",
    "\n",
    "    # Lemmatize\n",
    "    review = [token.lemma_ for token in nlp(review)]\n",
    "\n",
    "    # Remove stop words\n",
    "    review = [word for word in review if not word in stop_words]\n",
    "\n",
    "    # Rejoin the review words into one string\n",
    "    review = ' '.join(review)\n",
    "\n",
    "    return review\n",
    "\n",
    "def process_data(data, data_type):\n",
    "    \n",
    "    # Create a new DataFrame\n",
    "    cleaned_data = data.copy()    \n",
    "    \n",
    "    reviews = []\n",
    "    for i, review in enumerate(data['review']):\n",
    "        cleaned_review = cleanup(review)\n",
    "        reviews.append(cleaned_review)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Processing \"{data_type}\", {i} Review...')\n",
    "            \n",
    "    cleaned_data['review'] = reviews\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-start",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"Train Data\", 0 Review...\n",
      "Processing \"Train Data\", 100 Review...\n",
      "Processing \"Train Data\", 200 Review...\n",
      "Processing \"Train Data\", 300 Review...\n",
      "Processing \"Train Data\", 400 Review...\n",
      "Processing \"Train Data\", 500 Review...\n",
      "Processing \"Train Data\", 600 Review...\n",
      "Processing \"Train Data\", 700 Review...\n",
      "Processing \"Train Data\", 800 Review...\n",
      "Processing \"Train Data\", 900 Review...\n",
      "Processing \"Train Data\", 1000 Review...\n",
      "Processing \"Train Data\", 1100 Review...\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "cleaned_train_data = process_data(train_data, data_type = 'Train Data')\n",
    "cleaned_train_data.head(5)\n",
    "\n",
    "# Test Data\n",
    "cleaned_test_data = process_data(data = test_data, data_type = 'Test Data')\n",
    "cleaned_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-silence",
   "metadata": {},
   "source": [
    "## Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data.to_csv('Data/Processed/cleaned_labeledTrainData.csv', index = False)\n",
    "cleaned_test_data.to_csv('Data/Processed/cleaned_testData.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-albania",
   "metadata": {},
   "source": [
    "## Load the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data = pd.read_csv('Data/Processed/cleaned_labeledTrainData.csv')\n",
    "cleaned_test_data = pd.read_csv('Data/Processed/cleaned_testData.csv')\n",
    "\n",
    "cleaned_train_reviews = cleaned_train_data['review']\n",
    "cleaned_test_reviews = cleaned_test_data['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-horizontal",
   "metadata": {},
   "source": [
    "## Vectorize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-ordinance",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 5000)      # Top 5000 frequent words\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(cleaned_train_reviews)\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-matter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-wagner",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-break",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(cleaned_test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-bride",
   "metadata": {},
   "source": [
    "## Train the Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 100)\n",
    "random_forest = random_forest.fit(train_data_features, cleaned_train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-commonwealth",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = random_forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-tissue",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(data = {'id': cleaned_test_data['id'], 'sentiment': predictions})\n",
    "predictions_df.to_csv('Data/Processed/Submission.csv', index = False)\n",
    "predictions_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
